{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716d2911",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3372c4",
   "metadata": {},
   "source": [
    "early stopping을 넣었다고 하더라도\n",
    "운이 나쁘면(최적의 지점을 빨리 찾지 못하면) 에포크를 끝까지 다 돌아봐야 할 수도 있다는 것을 깨달았다.\n",
    "\n",
    "완전히 동일한 조건에서 아래 조건의 모델을 여러번 돌려봤을 때,  \n",
    "- 동일한 모델\n",
    "- epoch = 100\n",
    "- early stopping을 넣음\n",
    "\n",
    "어떨 땐 에포크 10만에 끝나기도 했고, 어떨 땐 에포크 100까지 전부 가야지만 끝나는 경우가 있었다.(생각해보면 당연한거지만...)\n",
    "\n",
    "에포크가 끝까지 돌아가는 경우가 많을 경우, 학습률을 조금 키우면 전체 에포크 수를 줄이는 것에 도움이 될 수 있을 듯 하다.   \n",
    "best 방법은, 아래 예시처럼 **\"학습률 스케쥴러\"**를 써서    \n",
    "monitor 지표의 개선이 없을 시 자동으로 학습률을 조정하는 방법을 쓰는 게 좋다고 한다.   \n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f4766",
   "metadata": {},
   "source": [
    "# Step 0. 필요한 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb342fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19c8d2",
   "metadata": {},
   "source": [
    "# Step 1. 데이터셋 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4fc1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ train 70%, val 15%, test 15%로 분할\n",
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b3925",
   "metadata": {},
   "source": [
    "# Step 2. 데이터셋을 모델에 넣을 수 있는 형태로 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9687550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 전처리 이유: EfficientNet은 (224, 224) 크기 + float 타입만 처리 가능\n",
    "IMG_SIZE = (224, 224)  # EfficientNet 기본 입력 크기\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = preprocess_input(image) # EfficientNet 전용 정규화 (/ 255.0 하면 안됨)\n",
    "    return image, label\n",
    "\n",
    "train_batches = ds_train.map(format_image, num_parallel_calls=AUTOTUNE).cache().shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "validation_batches = ds_validation.map(format_image, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_batches = ds_test.map(format_image, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db8efc",
   "metadata": {},
   "source": [
    "# Step 3. 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "121eacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ EfficientNet 모델 선정 이유:\n",
    "# - VGG16보다 정확도 우수 (VGG16도 실험했으나, 정확도 50% 수준이었음...)\n",
    "# - 파라미터 수 적고 모바일 환경에 최적화됨 (앱에 올릴거니까...)\n",
    "# - 최신 아키텍처 기반\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # ✅ Transfer learning - Feature Extractor 부분 동결\n",
    "\n",
    "# ✅ FC 레이어 설계 이유:\n",
    "# - Flatten 대신 GlobalAvgPooling: 파라미터 수 줄이기\n",
    "# - Dropout: overfitting 방지\n",
    "# - Dense(5): tf_flowers는 5개 클래스\n",
    "\n",
    "global_avg = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dropout = tf.keras.layers.Dropout(0.3)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax') # ✅ Dense layer(분류기) 부분만 학습\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_avg,\n",
    "    dropout,\n",
    "    output\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b33bc7",
   "metadata": {},
   "source": [
    "# Step 4. 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "166257ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81/81 [==============================] - 18s 95ms/step - loss: 1.5675 - accuracy: 0.3056 - val_loss: 1.2901 - val_accuracy: 0.5681\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 1.2118 - accuracy: 0.5660 - val_loss: 1.0271 - val_accuracy: 0.7205\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 1.0056 - accuracy: 0.6905 - val_loss: 0.8638 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.8614 - accuracy: 0.7571 - val_loss: 0.7560 - val_accuracy: 0.8058\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.7689 - accuracy: 0.7808 - val_loss: 0.6802 - val_accuracy: 0.8348\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.6976 - accuracy: 0.7980 - val_loss: 0.6231 - val_accuracy: 0.8421\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.6386 - accuracy: 0.8167 - val_loss: 0.5787 - val_accuracy: 0.8512\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.6017 - accuracy: 0.8163 - val_loss: 0.5430 - val_accuracy: 0.8512\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.5621 - accuracy: 0.8268 - val_loss: 0.5145 - val_accuracy: 0.8566\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.5297 - accuracy: 0.8470 - val_loss: 0.4880 - val_accuracy: 0.8639\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.5049 - accuracy: 0.8494 - val_loss: 0.4671 - val_accuracy: 0.8639\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.4772 - accuracy: 0.8571 - val_loss: 0.4491 - val_accuracy: 0.8711\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.4701 - accuracy: 0.8568 - val_loss: 0.4328 - val_accuracy: 0.8711\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.4479 - accuracy: 0.8669 - val_loss: 0.4178 - val_accuracy: 0.8730\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.4371 - accuracy: 0.8626 - val_loss: 0.4044 - val_accuracy: 0.8766\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.4210 - accuracy: 0.8750 - val_loss: 0.3922 - val_accuracy: 0.8766\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.4031 - accuracy: 0.8758 - val_loss: 0.3817 - val_accuracy: 0.8784\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3951 - accuracy: 0.8809 - val_loss: 0.3719 - val_accuracy: 0.8802\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3786 - accuracy: 0.8859 - val_loss: 0.3629 - val_accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3767 - accuracy: 0.8883 - val_loss: 0.3550 - val_accuracy: 0.8802\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3621 - accuracy: 0.8906 - val_loss: 0.3477 - val_accuracy: 0.8838\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.3505 - accuracy: 0.8945 - val_loss: 0.3411 - val_accuracy: 0.8838\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.3441 - accuracy: 0.8984 - val_loss: 0.3349 - val_accuracy: 0.8838\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3447 - accuracy: 0.8914 - val_loss: 0.3290 - val_accuracy: 0.8875\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3278 - accuracy: 0.9023 - val_loss: 0.3231 - val_accuracy: 0.8929\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3233 - accuracy: 0.9042 - val_loss: 0.3184 - val_accuracy: 0.8966\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3154 - accuracy: 0.9058 - val_loss: 0.3133 - val_accuracy: 0.8984\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3042 - accuracy: 0.9058 - val_loss: 0.3083 - val_accuracy: 0.9002\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3043 - accuracy: 0.9112 - val_loss: 0.3043 - val_accuracy: 0.9002\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3070 - accuracy: 0.9097 - val_loss: 0.3002 - val_accuracy: 0.9002\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2967 - accuracy: 0.9105 - val_loss: 0.2969 - val_accuracy: 0.9002\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2871 - accuracy: 0.9179 - val_loss: 0.2928 - val_accuracy: 0.9002\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2889 - accuracy: 0.9066 - val_loss: 0.2891 - val_accuracy: 0.9002\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2850 - accuracy: 0.9163 - val_loss: 0.2859 - val_accuracy: 0.9002\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2754 - accuracy: 0.9136 - val_loss: 0.2834 - val_accuracy: 0.9002\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2732 - accuracy: 0.9198 - val_loss: 0.2804 - val_accuracy: 0.9002\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2729 - accuracy: 0.9148 - val_loss: 0.2775 - val_accuracy: 0.9002\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2767 - accuracy: 0.9190 - val_loss: 0.2751 - val_accuracy: 0.9020\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2564 - accuracy: 0.9257 - val_loss: 0.2728 - val_accuracy: 0.9038\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2630 - accuracy: 0.9237 - val_loss: 0.2702 - val_accuracy: 0.9038\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2531 - accuracy: 0.9253 - val_loss: 0.2682 - val_accuracy: 0.9056\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2586 - accuracy: 0.9190 - val_loss: 0.2659 - val_accuracy: 0.9074\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2526 - accuracy: 0.9276 - val_loss: 0.2640 - val_accuracy: 0.9056\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2496 - accuracy: 0.9229 - val_loss: 0.2620 - val_accuracy: 0.9056\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2424 - accuracy: 0.9315 - val_loss: 0.2603 - val_accuracy: 0.9056\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2468 - accuracy: 0.9249 - val_loss: 0.2585 - val_accuracy: 0.9074\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2466 - accuracy: 0.9245 - val_loss: 0.2565 - val_accuracy: 0.9056\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2325 - accuracy: 0.9350 - val_loss: 0.2540 - val_accuracy: 0.9074\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2292 - accuracy: 0.9393 - val_loss: 0.2528 - val_accuracy: 0.9038\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2295 - accuracy: 0.9288 - val_loss: 0.2512 - val_accuracy: 0.9038\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2371 - accuracy: 0.9295 - val_loss: 0.2500 - val_accuracy: 0.9074\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2298 - accuracy: 0.9249 - val_loss: 0.2487 - val_accuracy: 0.9093\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2249 - accuracy: 0.9354 - val_loss: 0.2471 - val_accuracy: 0.9056\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2231 - accuracy: 0.9299 - val_loss: 0.2458 - val_accuracy: 0.9093\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2229 - accuracy: 0.9362 - val_loss: 0.2447 - val_accuracy: 0.9093\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2071 - accuracy: 0.9377 - val_loss: 0.2437 - val_accuracy: 0.9074\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2071 - accuracy: 0.9416 - val_loss: 0.2423 - val_accuracy: 0.9056\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.2111 - accuracy: 0.9412 - val_loss: 0.2416 - val_accuracy: 0.9056\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.2059 - accuracy: 0.9377 - val_loss: 0.2405 - val_accuracy: 0.9074\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.2016 - accuracy: 0.9436 - val_loss: 0.2390 - val_accuracy: 0.9074\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1999 - accuracy: 0.9443 - val_loss: 0.2380 - val_accuracy: 0.9056\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1994 - accuracy: 0.9447 - val_loss: 0.2369 - val_accuracy: 0.9074\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.1987 - accuracy: 0.9397 - val_loss: 0.2358 - val_accuracy: 0.9074\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2059 - accuracy: 0.9385 - val_loss: 0.2343 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 6s 74ms/step - loss: 0.2037 - accuracy: 0.9404 - val_loss: 0.2335 - val_accuracy: 0.9074\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1924 - accuracy: 0.9420 - val_loss: 0.2324 - val_accuracy: 0.9093\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1967 - accuracy: 0.9412 - val_loss: 0.2313 - val_accuracy: 0.9074\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1872 - accuracy: 0.9482 - val_loss: 0.2310 - val_accuracy: 0.9074\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1925 - accuracy: 0.9393 - val_loss: 0.2298 - val_accuracy: 0.9056\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1935 - accuracy: 0.9428 - val_loss: 0.2290 - val_accuracy: 0.9093\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1780 - accuracy: 0.9513 - val_loss: 0.2279 - val_accuracy: 0.9093\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1915 - accuracy: 0.9475 - val_loss: 0.2272 - val_accuracy: 0.9074\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1863 - accuracy: 0.9416 - val_loss: 0.2260 - val_accuracy: 0.9074\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1857 - accuracy: 0.9475 - val_loss: 0.2250 - val_accuracy: 0.9093\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1836 - accuracy: 0.9447 - val_loss: 0.2242 - val_accuracy: 0.9093\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1842 - accuracy: 0.9420 - val_loss: 0.2228 - val_accuracy: 0.9074\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1775 - accuracy: 0.9467 - val_loss: 0.2224 - val_accuracy: 0.9093\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1803 - accuracy: 0.9502 - val_loss: 0.2218 - val_accuracy: 0.9111\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1740 - accuracy: 0.9471 - val_loss: 0.2214 - val_accuracy: 0.9111\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1782 - accuracy: 0.9471 - val_loss: 0.2210 - val_accuracy: 0.9111\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1768 - accuracy: 0.9463 - val_loss: 0.2203 - val_accuracy: 0.9074\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1668 - accuracy: 0.9533 - val_loss: 0.2198 - val_accuracy: 0.9074\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1720 - accuracy: 0.9486 - val_loss: 0.2191 - val_accuracy: 0.9093\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1769 - accuracy: 0.9455 - val_loss: 0.2181 - val_accuracy: 0.9093\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 0.1695 - accuracy: 0.9455 - val_loss: 0.2174 - val_accuracy: 0.9093\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1705 - accuracy: 0.9506 - val_loss: 0.2169 - val_accuracy: 0.9093\n",
      "Epoch 87/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1621 - accuracy: 0.9541 - val_loss: 0.2161 - val_accuracy: 0.9093\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1690 - accuracy: 0.9545 - val_loss: 0.2159 - val_accuracy: 0.9093\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1653 - accuracy: 0.9475 - val_loss: 0.2154 - val_accuracy: 0.9111\n",
      "Epoch 90/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1687 - accuracy: 0.9502 - val_loss: 0.2145 - val_accuracy: 0.9093\n",
      "Epoch 91/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1715 - accuracy: 0.9459 - val_loss: 0.2140 - val_accuracy: 0.9111\n",
      "Epoch 92/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1661 - accuracy: 0.9494 - val_loss: 0.2131 - val_accuracy: 0.9111\n",
      "Epoch 93/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1632 - accuracy: 0.9482 - val_loss: 0.2130 - val_accuracy: 0.9111\n",
      "Epoch 94/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1565 - accuracy: 0.9572 - val_loss: 0.2127 - val_accuracy: 0.9093\n",
      "Epoch 95/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1600 - accuracy: 0.9580 - val_loss: 0.2130 - val_accuracy: 0.9111\n",
      "Epoch 96/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1535 - accuracy: 0.9583 - val_loss: 0.2123 - val_accuracy: 0.9111\n",
      "Epoch 97/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1582 - accuracy: 0.9541 - val_loss: 0.2122 - val_accuracy: 0.9111\n",
      "Epoch 98/100\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.1534 - accuracy: 0.9560 - val_loss: 0.2128 - val_accuracy: 0.9129\n",
      "Epoch 99/100\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1558 - accuracy: 0.9560 - val_loss: 0.2118 - val_accuracy: 0.9093\n",
      "Epoch 100/100\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1549 - accuracy: 0.9521 - val_loss: 0.2111 - val_accuracy: 0.9093\n"
     ]
    }
   ],
   "source": [
    "# ✅ 하이퍼파라미터 선정 이유:\n",
    "# - Adam: 빠른 수렴\n",
    "# - Learning Rate 0.0001: 과적합 최소화\n",
    "# - Loss: sparse_categorical_crossentropy → 라벨이 정수로 제공됨\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ✅ 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # 검증 손실 기준 (정확도보다 손실이 노이즈에 덜 민감하며 변화 감지에 강함)\n",
    "    patience=3,              # 3 epoch 동안 개선 없으면 멈춤\n",
    "    restore_best_weights=True  # 가장 좋았던 weight 복원\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    validation_data=validation_batches,\n",
    "    epochs=100,  # 10 -> 15 에포크 증가시키면서 성능 개선 확인하였으며, 아예100으로 늘리고 early stopping을 넣는 방향으로 개선하였음\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd7e87",
   "metadata": {},
   "source": [
    "# Step 5. 모델 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8da57985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1795 - accuracy: 0.9364\n",
      "\n",
      "✅ Test Accuracy: 93.64%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy Curve')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss Curve')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_plot.png\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_batches)\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a68daa",
   "metadata": {},
   "source": [
    "# Step 6. 모델 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e520c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_flower_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_flower_model/assets\n",
      "/opt/conda/lib/python3.9/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1412933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1378548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1411653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1378365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1380134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1379686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1412696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1409297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1409126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1404392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1411719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1378273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1404563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1376953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1377011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1406141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1412326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1408756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1405211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1379421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1378497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1380042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1410464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1378100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1407912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1379645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1408149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1409363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1402382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1413303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1404952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1378589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1377492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1378930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1405145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1407523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1376836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1380093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_1404135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1376795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_2_layer_call_and_return_conditional_losses_1399510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1379594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1408690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1377701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1378049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1413863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1377660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1412089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1405771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_2_layer_call_and_return_conditional_losses_1397740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1410293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1412260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1377451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1377932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1379370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1377052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1411482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1379910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1377169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1409923) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1379022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1406334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1379462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1378981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1413474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1378757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1409857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1406400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1377833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1405534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1369443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1378798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1408083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1379818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1377609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1378141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1377220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1377891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1407589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1379154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1377393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1408519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1379212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1409686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1378324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1411159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1377261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1406894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1379869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1404629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1410530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1406723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1413540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1380251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1379253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1405705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1410900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1407330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1411093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1378706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1376744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1412867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1406960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy_test.jpg → daisy (84.22%)\n",
      "dandelion_test.jpg → dandelion (100.00%)\n",
      "rose_test.jpeg → roses (86.71%)\n",
      "sunflower_test.jpeg → sunflowers (82.63%)\n",
      "tulip_test.jpg → tulips (98.60%)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 모델 저장 (Flutter 연동 위해 TFLite 변환 구조로 저장)\n",
    "model_dir = \"efficientnet_flower_model\"\n",
    "model.save(model_dir)\n",
    "\n",
    "# TFLite 변환\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"efficientnet_flower_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "    \n",
    "    \n",
    "# ✅ 인터넷에서 가져온 이미지 실험해보기\n",
    "builder = tfds.builder('tf_flowers')\n",
    "class_names = builder.info.features['label'].names\n",
    "\n",
    "# ✅ 테스트 이미지 파일 리스트\n",
    "image_paths = [\n",
    "    'daisy_test.jpg',\n",
    "    'dandelion_test.jpg',\n",
    "    'rose_test.jpeg',\n",
    "    'sunflower_test.jpeg',\n",
    "    'tulip_test.jpg'\n",
    "]\n",
    "\n",
    "# ✅ 하나씩 예측해보기\n",
    "for img_path in image_paths:\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # EfficientNet용 전처리\n",
    "    from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    class_idx = np.argmax(preds[0])\n",
    "    confidence = preds[0][class_idx]\n",
    "    label = class_names[class_idx]\n",
    "\n",
    "    print(f\"{img_path} → {label} ({confidence:.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
